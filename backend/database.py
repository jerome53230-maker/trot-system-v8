"""
Database Module - PostgreSQL avec toutes optimisations
Trot System v8.3 FINAL
"""

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.pool import QueuePool
from contextlib import contextmanager
from datetime import datetime
import logging

from config import Config

logger = logging.getLogger('trot-system.database')

# Base pour mod√®les
Base = declarative_base()

# Engine et Session
engine = None
SessionLocal = None


def init_database():
    """
    Initialise connexion PostgreSQL avec pool optimis√©.
    
    Returns:
        bool: True si succ√®s, False sinon
    """
    global engine, SessionLocal
    
    try:
        if not Config.DATABASE_URL:
            logger.warning("‚ö†Ô∏è DATABASE_URL non configur√©e - Mode sans DB")
            return False
        
        # Cr√©er engine avec pool optimis√©
        engine = create_engine(
            Config.DATABASE_URL,
            poolclass=QueuePool,
            pool_size=Config.DB_POOL_SIZE,
            max_overflow=Config.DB_MAX_OVERFLOW,
            pool_pre_ping=True,  # Test connexion avant utilisation
            pool_recycle=Config.DB_POOL_RECYCLE,  # Recycle apr√®s 1h
            echo=False,  # Pas de logs SQL (performance)
            connect_args={
                'connect_timeout': 10,
                'application_name': 'trot-system'
            }
        )
        
        # Tester connexion
        with engine.connect() as conn:
            conn.execute("SELECT 1")
        
        # Cr√©er session factory
        SessionLocal = scoped_session(
            sessionmaker(
                autocommit=False,
                autoflush=False,
                bind=engine
            )
        )
        
        logger.info("‚úÖ Connexion PostgreSQL √©tablie")
        return True
    
    except Exception as e:
        logger.error(f"‚ùå Erreur init database: {e}")
        return False


@contextmanager
def get_db():
    """
    Context manager pour sessions DB avec gestion automatique.
    
    Usage:
        with get_db() as db:
            db.query(Model).all()
    """
    if not SessionLocal:
        raise RuntimeError("Database non initialis√©e. Appelez init_database() d'abord.")
    
    db = SessionLocal()
    try:
        yield db
        db.commit()
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå Erreur DB transaction: {e}")
        raise
    finally:
        db.close()


def test_connection() -> bool:
    """
    Teste si connexion DB fonctionne.
    
    Returns:
        bool: True si OK, False sinon
    """
    if not engine:
        return False
    
    try:
        with engine.connect() as conn:
            result = conn.execute("SELECT 1")
            return result.fetchone()[0] == 1
    except Exception as e:
        logger.error(f"‚ùå Test connexion √©chou√©: {e}")
        return False


def get_db_stats() -> dict:
    """
    Retourne statistiques database.
    
    Returns:
        dict: Stats (tables, rows, size)
    """
    if not engine:
        return {}
    
    try:
        with get_db() as db:
            # Importer ici pour √©viter circular import
            from models import Analyse, Performance, CoursesCache, Statistic
            
            stats = {
                'analyses': db.query(Analyse).count(),
                'performances': db.query(Performance).count(),
                'cache': db.query(CoursesCache).count(),
                'statistics': db.query(Statistic).count()
            }
            
            # Taille DB (PostgreSQL)
            try:
                result = db.execute(
                    "SELECT pg_size_pretty(pg_database_size(current_database()))"
                )
                stats['database_size'] = result.scalar()
            except:
                stats['database_size'] = 'N/A'
            
            return stats
    
    except Exception as e:
        logger.error(f"‚ùå Erreur get_db_stats: {e}")
        return {}


def clean_expired_cache(batch_size: int = 100) -> int:
    """
    Nettoie cache expir√© par batch (optimis√©).
    
    Args:
        batch_size: Taille des batchs de suppression
        
    Returns:
        int: Nombre d'entr√©es supprim√©es
    """
    if not engine:
        return 0
    
    try:
        from models import CoursesCache
        
        total_deleted = 0
        
        with get_db() as db:
            while True:
                # Supprimer par batch (√©vite lock table)
                deleted = db.query(CoursesCache).filter(
                    CoursesCache.expires_at < datetime.now()
                ).limit(batch_size).delete(synchronize_session=False)
                
                db.commit()
                total_deleted += deleted
                
                if deleted < batch_size:
                    break
        
        if total_deleted > 0:
            logger.info(f"üßπ Cache nettoy√©: {total_deleted} entr√©es expir√©es")
        
        return total_deleted
    
    except Exception as e:
        logger.error(f"‚ùå Erreur clean_expired_cache: {e}")
        return 0


def vacuum_database():
    """
    Lance VACUUM sur database (maintenance PostgreSQL).
    """
    if not engine:
        return
    
    try:
        # VACUUM n√©cessite autocommit
        connection = engine.raw_connection()
        connection.set_isolation_level(0)  # Autocommit
        cursor = connection.cursor()
        cursor.execute("VACUUM ANALYZE")
        connection.close()
        
        logger.info("‚úÖ VACUUM database termin√©")
    
    except Exception as e:
        logger.error(f"‚ùå Erreur VACUUM: {e}")


def close_database():
    """
    Ferme proprement connexions database.
    """
    global engine, SessionLocal
    
    try:
        if SessionLocal:
            SessionLocal.remove()
        
        if engine:
            engine.dispose()
        
        logger.info("‚úÖ Connexions database ferm√©es")
    
    except Exception as e:
        logger.error(f"‚ùå Erreur fermeture database: {e}")


def create_tables():
    """
    Cr√©e toutes les tables (pour d√©veloppement).
    En production, utiliser Alembic migrations.
    """
    if not engine:
        logger.error("‚ùå Engine non initialis√©")
        return False
    
    try:
        Base.metadata.create_all(bind=engine)
        logger.info("‚úÖ Tables cr√©√©es")
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation tables: {e}")
        return False


# Fonctions utilitaires

def execute_raw_sql(sql: str, params: dict = None):
    """
    Ex√©cute SQL brut (√† utiliser avec pr√©caution).
    
    Args:
        sql: Requ√™te SQL
        params: Param√®tres (s√©curis√©)
    """
    if not engine:
        raise RuntimeError("Database non initialis√©e")
    
    with engine.connect() as conn:
        if params:
            result = conn.execute(sql, params)
        else:
            result = conn.execute(sql)
        return result


def get_table_row_counts() -> dict:
    """
    Retourne nombre de lignes par table.
    """
    if not engine:
        return {}
    
    try:
        tables = ['analyses', 'performances', 'courses_cache', 'statistics']
        counts = {}
        
        with engine.connect() as conn:
            for table in tables:
                result = conn.execute(f"SELECT COUNT(*) FROM {table}")
                counts[table] = result.scalar()
        
        return counts
    
    except Exception as e:
        logger.error(f"‚ùå Erreur get_table_row_counts: {e}")
        return {}


# Monitoring

class DatabaseMetrics:
    """Classe pour m√©triques database."""
    
    def __init__(self):
        self.query_count = 0
        self.total_query_time = 0.0
    
    def record_query(self, duration: float):
        """Enregistre dur√©e query."""
        self.query_count += 1
        self.total_query_time += duration
    
    def get_avg_query_time(self) -> float:
        """Retourne temps moyen query."""
        if self.query_count == 0:
            return 0.0
        return self.total_query_time / self.query_count
    
    def reset(self):
        """Reset m√©triques."""
        self.query_count = 0
        self.total_query_time = 0.0


# Instance globale m√©triques
db_metrics = DatabaseMetrics()


if __name__ == '__main__':
    # Test connexion
    logging.basicConfig(level=logging.INFO)
    
    if init_database():
        print("‚úÖ Test connexion OK")
        print(f"Stats: {get_db_stats()}")
        close_database()
    else:
        print("‚ùå Test connexion √©chou√©")
